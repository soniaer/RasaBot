{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "\n",
    "# PostgreSQL URL\n",
    "os.environ[\"DATABASE_URL\"] = \"postgresql://postgres:password@localhost:5432\"\n",
    "postgres_url = os.environ.get(\"DATABASE_URL\")\n",
    "db_name = \"rasa_prod\"\n",
    "\n",
    "# # Connect to PostgreSQL and create the new database\n",
    "# conn = psycopg2.connect(postgres_url)\n",
    "# conn.autocommit = True\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Create a new database\n",
    "# cursor.execute(sql.SQL(\"CREATE DATABASE {}\").format(sql.Identifier(db_name)))\n",
    "\n",
    "# # Close the initial connection\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "\n",
    "# # Connect to the newly created database\n",
    "# conn = psycopg2.connect(f\"{postgres_url}/{db_name}\")\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Create the CARD_PROD table\n",
    "# cursor.execute(\"\"\"\n",
    "#     CREATE TABLE CARD_PROD (\n",
    "#         Card_Prod_ID VARCHAR(3) PRIMARY KEY,\n",
    "#         Cust_Face_Prod_NM VARCHAR(45)\n",
    "#     )\n",
    "# \"\"\")\n",
    "\n",
    "# # Create the CARD_PROD_FETR table\n",
    "# cursor.execute(\"\"\"\n",
    "#     CREATE TABLE CARD_PROD_FETR (\n",
    "#         Card_Prod_ID VARCHAR(3),\n",
    "#         Card_Prod_FETR_CD VARCHAR(40),\n",
    "#         Card_Prod_FETR_Type VARCHAR(50),\n",
    "#         Card_Prod_FETR_Desc VARCHAR(600),\n",
    "#         FOREIGN KEY (Card_Prod_ID) REFERENCES CARD_PROD(Card_Prod_ID)\n",
    "#     )\n",
    "# \"\"\")\n",
    "\n",
    "# # Insert data into CARD_PROD table\n",
    "# card_prod_data = [\n",
    "#     ('001', 'Disney'),\n",
    "#     ('002', 'Freedom'),\n",
    "#     ('003', 'Sapphire')\n",
    "# ]\n",
    "\n",
    "# cursor.executemany(\"\"\"\n",
    "#     INSERT INTO CARD_PROD (Card_Prod_ID, Cust_Face_Prod_NM)\n",
    "#     VALUES (%s, %s)\n",
    "# \"\"\", card_prod_data)\n",
    "\n",
    "# # Insert data into CARD_PROD_FETR table\n",
    "# card_prod_fetr_data = [\n",
    "#     ('001', 'Annual_Fee', 'Optional_Feature', 'Annual Fee Charged on this card is 25 USD annually'),\n",
    "#     ('001', 'Cash_Back', 'Mandatory_Feature', 'Cash back of 2% on grocery purchases,5% on Retail'),\n",
    "#     ('001', 'Purchase_Protection', 'Complimentary_Benefit', 'Purchase protection for purchases above 500USD'),\n",
    "#     ('001', 'BuyNowPayLater', 'Complimentary_Benefit', 'Payment Plan for any purchase above 100USD'),\n",
    "#     ('001', 'ApplyByPhone', 'Optional_Feature', 'Card Onboarding and activation by phone'),\n",
    "#     ('002', 'Annual_Fee', 'Optional_Feature', 'No Annual Fee'),\n",
    "#     ('002', 'Cash_Back', 'Mandatory_Feature', 'Cash back of 2% on grocery purchases,5% on Retail'),\n",
    "#     ('003', 'Annual_Fee', 'Optional_Feature', 'Annual Fee Charged on this card is 625 USD annually'),\n",
    "#     ('003', 'Cash_Back', 'Mandatory_Feature', 'Cash back of 5% on grocery purchases,5% on Retail,10% on Airline Ticket Purchase'),\n",
    "#     ('003', 'Purchase_Protection', 'Complimentary_Benefit', 'Purchase protection for purchases above 500USD'),\n",
    "#     ('003', 'BuyNowPayLater', 'Complimentary_Benefit', 'Payment Plan for any purchase above 100USD'),\n",
    "#     ('003', 'ApplyByPhone', 'Optional_Feature', 'Card Onboarding and activation by phone'),\n",
    "#     ('003', 'AirlineMile', 'Complimentary_Benefit', 'Statement Point to be converted to Airline Miles'),\n",
    "#     ('003', 'StatementCredit', 'Complimentary_Benefit', 'TSA pre-check credit per year upto 100'),\n",
    "#     ('003', 'Travel_Lounge', 'Complimentary_Benefit', 'Free Access to Lounges across the globe'),\n",
    "#     ('003', 'PayByPhone', 'Optional_Feature', 'Card Payment by phone')\n",
    "# ]\n",
    "\n",
    "# cursor.executemany(\"\"\"\n",
    "#     INSERT INTO CARD_PROD_FETR (Card_Prod_ID, Card_Prod_FETR_CD, Card_Prod_FETR_Type, Card_Prod_FETR_Desc)\n",
    "#     VALUES (%s, %s, %s, %s)\n",
    "# \"\"\", card_prod_fetr_data)\n",
    "\n",
    "# # Commit the transactions\n",
    "# conn.commit()\n",
    "\n",
    "# # Close the connection\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/d5gdm5pd59n_zm40m7hv4kpc0000gn/T/ipykernel_45436/4104637104.py:35: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")\n",
      "/Users/abhishek/miniconda3/envs/llama/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import SQLDatabase, ServiceContext\n",
    "from llama_index.core.objects import SQLTableNodeMapping, ObjectIndex, SQLTableSchema\n",
    "from llama_index.core.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex\n",
    "import logging\n",
    "\n",
    "from llama_index.core.output_parsers import LangchainOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# PostgreSQL URL\n",
    "os.environ[\"DATABASE_URL\"] = \"postgresql://postgres:password@localhost:5432\"\n",
    "postgres_url = os.environ.get(\"DATABASE_URL\")\n",
    "db_name = \"rasa_prod\"\n",
    "\n",
    "output_parser = LangchainOutputParser(JsonOutputParser())\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "engine = create_engine(f\"{postgres_url}/{db_name}\")\n",
    "\n",
    "# Choose LLM and configure ServiceContext\n",
    "llm = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"), model=\"gpt-4o-mini\", output_parser=output_parser)\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# llm = Ollama(model=\"llama2:7b-chat\", request_timeout=60.0)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm)#, embed_model=\"local\")\n",
    "\n",
    "# Define the tables and create SQLDatabase object\n",
    "tables = [\n",
    "    {\n",
    "        \"table_name\": \"card_prod\", \n",
    "        \"context\": \"List of card products, contains product ID and customer-facing product name.\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"card_prod_fetr\", \n",
    "        \"context\": \"List of product features associated with card products from(card_prod), contains product ID, feature code, feature type, and feature description.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "sql_database = SQLDatabase(\n",
    "    engine, include_tables=[table[\"table_name\"] for table in tables]\n",
    ")\n",
    "\n",
    "# Create table node mapping and object index\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    SQLTableSchema(table_name=table[\"table_name\"], context_str=table[\"context\"])\n",
    "    for table in tables\n",
    "]\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "\n",
    "sql_retriever = SQLRetriever(sql_database)\n",
    "\n",
    "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
    "    \"\"\"Get table context string.\"\"\"\n",
    "    context_strs = []\n",
    "    for table_schema_obj in table_schema_objs:\n",
    "        table_info = sql_database.get_single_table_info(\n",
    "            table_schema_obj.table_name\n",
    "        )\n",
    "        if table_schema_obj.context_str:\n",
    "            table_opt_context = \" The table description is: \"\n",
    "            table_opt_context += table_schema_obj.context_str\n",
    "            table_info += table_opt_context\n",
    "\n",
    "        context_strs.append(table_info)\n",
    "    return \"\\n\\n\".join(context_strs)\n",
    "\n",
    "\n",
    "table_parser_component = FnComponent(fn=get_table_context_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "from llama_index.core.llms import ChatResponse\n",
    "\n",
    "\n",
    "def parse_response_to_sql(response: ChatResponse) -> str:\n",
    "    \"\"\"Parse response to SQL.\"\"\"\n",
    "    response = response.message.content\n",
    "    sql_query_start = response.find(\"SQLQuery:\")\n",
    "    if sql_query_start != -1:\n",
    "        response = response[sql_query_start:]\n",
    "        # TODO: move to removeprefix after Python 3.9+\n",
    "        if response.startswith(\"SQLQuery:\"):\n",
    "            response = response[len(\"SQLQuery:\") :]\n",
    "    sql_result_start = response.find(\"SQLResult:\")\n",
    "    if sql_result_start != -1:\n",
    "        response = response[:sql_result_start]\n",
    "    return response.strip().strip(\"```\").strip()\n",
    "\n",
    "\n",
    "sql_parser_component = FnComponent(fn=parse_response_to_sql)\n",
    "\n",
    "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
    "    dialect=engine.dialect.name\n",
    ")\n",
    "# print(text2sql_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"SQL: {sql_query}\\n\"\n",
    "    \"SQL Response: {context_str}\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "response_synthesis_prompt = PromptTemplate(\n",
    "    response_synthesis_prompt_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.query_pipeline import (\n",
    "#     QueryPipeline as QP,\n",
    "#     Link,\n",
    "#     InputComponent,\n",
    "#     CustomQueryComponent,\n",
    "# )\n",
    "\n",
    "# qp = QP(\n",
    "#     modules={\n",
    "#         \"input\": InputComponent(),\n",
    "#         \"table_retriever\": obj_retriever,\n",
    "#         \"table_output_parser\": table_parser_component,\n",
    "#         \"text2sql_prompt\": text2sql_prompt,\n",
    "#         \"text2sql_llm\": llm,\n",
    "#         \"sql_output_parser\": sql_parser_component,\n",
    "#         \"sql_retriever\": sql_retriever,\n",
    "#         \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "#         \"response_synthesis_llm\": llm,\n",
    "#     },\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# qp.add_chain([\"input\", \"table_retriever\", \"table_output_parser\"])\n",
    "# qp.add_link(\"input\", \"text2sql_prompt\", dest_key=\"query_str\")\n",
    "# qp.add_link(\"table_output_parser\", \"text2sql_prompt\", dest_key=\"schema\")\n",
    "# qp.add_chain(\n",
    "#     [\"text2sql_prompt\", \"text2sql_llm\", \"sql_output_parser\", \"sql_retriever\"]\n",
    "# )\n",
    "# qp.add_link(\n",
    "#     \"sql_output_parser\", \"response_synthesis_prompt\", dest_key=\"sql_query\"\n",
    "# )\n",
    "# qp.add_link(\n",
    "#     \"sql_retriever\", \"response_synthesis_prompt\", dest_key=\"context_str\"\n",
    "# )\n",
    "# qp.add_link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\")\n",
    "# qp.add_link(\"response_synthesis_prompt\", \"response_synthesis_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = qp.run(\n",
    "#     query=\"look for the word cashback or cash or discount\"\n",
    "# )\n",
    "# print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing rows in table: card_prod\n",
      "Indexing rows in table: card_prod_fetr\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, load_index_from_storage\n",
    "from sqlalchemy import text\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import StorageContext\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def index_all_tables(\n",
    "    sql_database: SQLDatabase, table_index_dir: str = \"table_index_dir\"\n",
    ") -> Dict[str, VectorStoreIndex]:\n",
    "    \"\"\"Index all tables.\"\"\"\n",
    "    if not Path(table_index_dir).exists():\n",
    "        os.makedirs(table_index_dir)\n",
    "\n",
    "    vector_index_dict = {}\n",
    "    engine = sql_database.engine\n",
    "    for table_name in sql_database.get_usable_table_names():\n",
    "        print(f\"Indexing rows in table: {table_name}\")\n",
    "        if not os.path.exists(f\"{table_index_dir}/{table_name}\"):\n",
    "            # get all rows from table\n",
    "            with engine.connect() as conn:\n",
    "                cursor = conn.execute(text(f'SELECT * FROM \"{table_name}\"'))\n",
    "                result = cursor.fetchall()\n",
    "                row_tups = []\n",
    "                for row in result:\n",
    "                    row_tups.append(tuple(row))\n",
    "\n",
    "            # index each row, put into vector store index\n",
    "            nodes = [TextNode(text=str(t)) for t in row_tups]\n",
    "\n",
    "            # put into vector store index (use OpenAIEmbeddings by default)\n",
    "            index = VectorStoreIndex(nodes)\n",
    "\n",
    "            # save index\n",
    "            index.set_index_id(\"vector_index\")\n",
    "            index.storage_context.persist(f\"{table_index_dir}/{table_name}\")\n",
    "        else:\n",
    "            # rebuild storage context\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                persist_dir=f\"{table_index_dir}/{table_name}\"\n",
    "            )\n",
    "            # load index\n",
    "            index = load_index_from_storage(\n",
    "                storage_context, index_id=\"vector_index\"\n",
    "            )\n",
    "        vector_index_dict[table_name] = index\n",
    "\n",
    "    return vector_index_dict\n",
    "\n",
    "\n",
    "vector_index_dict = index_all_tables(sql_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "\n",
    "sql_retriever = SQLRetriever(sql_database)\n",
    "\n",
    "\n",
    "def get_table_context_and_rows_str(\n",
    "    query_str: str, table_schema_objs: List[SQLTableSchema]\n",
    "):\n",
    "    \"\"\"Get table context string.\"\"\"\n",
    "    context_strs = []\n",
    "    for table_schema_obj in table_schema_objs:\n",
    "        # first append table info + additional context\n",
    "        table_info = sql_database.get_single_table_info(\n",
    "            table_schema_obj.table_name\n",
    "        )\n",
    "        if table_schema_obj.context_str:\n",
    "            table_opt_context = \" The table description is: \"\n",
    "            table_opt_context += table_schema_obj.context_str\n",
    "            table_info += table_opt_context\n",
    "\n",
    "        # also lookup vector index to return relevant table rows\n",
    "        vector_retriever = vector_index_dict[\n",
    "            table_schema_obj.table_name\n",
    "        ].as_retriever(similarity_top_k=2)\n",
    "        relevant_nodes = vector_retriever.retrieve(query_str)\n",
    "        if len(relevant_nodes) > 0:\n",
    "            table_row_context = \"\\nHere are some relevant example rows (values in the same order as columns above)\\n\"\n",
    "            for node in relevant_nodes:\n",
    "                table_row_context += str(node.get_content()) + \"\\n\"\n",
    "            table_info += table_row_context\n",
    "\n",
    "        context_strs.append(table_info)\n",
    "    return \"\\n\\n\".join(context_strs)\n",
    "\n",
    "\n",
    "table_parser_component = FnComponent(fn=get_table_context_and_rows_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    "    CustomQueryComponent,\n",
    ")\n",
    "\n",
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"table_retriever\": obj_retriever,\n",
    "        \"table_output_parser\": table_parser_component,\n",
    "        \"text2sql_prompt\": text2sql_prompt,\n",
    "        \"text2sql_llm\": llm,\n",
    "        \"sql_output_parser\": sql_parser_component,\n",
    "        \"sql_retriever\": sql_retriever,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"response_synthesis_llm\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "qp.add_link(\"input\", \"table_retriever\")\n",
    "qp.add_link(\"input\", \"table_output_parser\", dest_key=\"query_str\")\n",
    "qp.add_link(\n",
    "    \"table_retriever\", \"table_output_parser\", dest_key=\"table_schema_objs\"\n",
    ")\n",
    "qp.add_link(\"input\", \"text2sql_prompt\", dest_key=\"query_str\")\n",
    "qp.add_link(\"table_output_parser\", \"text2sql_prompt\", dest_key=\"schema\")\n",
    "qp.add_chain(\n",
    "    [\"text2sql_prompt\", \"text2sql_llm\", \"sql_output_parser\", \"sql_retriever\"]\n",
    ")\n",
    "qp.add_link(\n",
    "    \"sql_output_parser\", \"response_synthesis_prompt\", dest_key=\"sql_query\"\n",
    ")\n",
    "qp.add_link(\n",
    "    \"sql_retriever\", \"response_synthesis_prompt\", dest_key=\"context_str\"\n",
    ")\n",
    "qp.add_link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\")\n",
    "qp.add_link(\"response_synthesis_prompt\", \"response_synthesis_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query: show cashback option or retail discount\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module table_retriever with input: \n",
      "input: show cashback option or retail discount\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module table_output_parser with input: \n",
      "query_str: show cashback option or retail discount\n",
      "table_schema_objs: [SQLTableSchema(table_name='card_prod', context_str='List of card products, contains product ID and customer-facing product name.'), SQLTableSchema(table_name='card_prod_fetr', context_str='List of pr...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module text2sql_prompt with input: \n",
      "query_str: show cashback option or retail discount\n",
      "schema: Table 'card_prod' has columns: card_prod_id (VARCHAR(3)), cust_face_prod_nm (VARCHAR(45)), and foreign keys: . The table description is: List of card products, contains product ID and customer-facing ...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module text2sql_llm with input: \n",
      "messages: Given an input question, first create a syntactically correct postgresql query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to re...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_output_parser with input: \n",
      "response: assistant: SQLQuery: SELECT cp.cust_face_prod_nm, cpf.card_prod_fetr_desc \n",
      "FROM card_prod cp \n",
      "JOIN card_prod_fetr cpf ON cp.card_prod_id = cpf.card_prod_id \n",
      "WHERE cpf.card_prod_fetr_cd = 'Cash_Back' O...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_retriever with input: \n",
      "input: SELECT cp.cust_face_prod_nm, cpf.card_prod_fetr_desc \n",
      "FROM card_prod cp \n",
      "JOIN card_prod_fetr cpf ON cp.card_prod_id = cpf.card_prod_id \n",
      "WHERE cpf.card_prod_fetr_cd = 'Cash_Back' OR cpf.card_prod_fetr_...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: show cashback option or retail discount\n",
      "sql_query: SELECT cp.cust_face_prod_nm, cpf.card_prod_fetr_desc \n",
      "FROM card_prod cp \n",
      "JOIN card_prod_fetr cpf ON cp.card_prod_id = cpf.card_prod_id \n",
      "WHERE cpf.card_prod_fetr_cd = 'Cash_Back' OR cpf.card_prod_fetr_...\n",
      "context_str: [NodeWithScore(node=TextNode(id_='4a5be640-a523-4d5b-b111-618ce7268784', embedding=None, metadata={'sql_query': \"SELECT cp.cust_face_prod_nm, cpf.card_prod_fetr_desc \\nFROM card_prod cp \\nJOIN card_pr...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_llm with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: show cashback option or retail discount\n",
      "SQL: SELECT cp.cust_face_prod_nm, cpf.card_prod_fetr_desc \n",
      "FROM card_prod cp \n",
      "JOIN...\n",
      "\n",
      "\u001b[0massistant: The available options for cashback or retail discounts include:\n",
      "\n",
      "1. **Disney Card**: Offers a cash back of 2% on grocery purchases and 5% on retail.\n",
      "2. **Freedom Card**: Provides a cash back of 2% on grocery purchases and 5% on retail.\n",
      "3. **Sapphire Card**: Features a cash back of 5% on grocery purchases, 5% on retail, and 10% on airline ticket purchases.\n",
      "\n",
      "These cards provide various benefits for both grocery and retail spending.\n"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query=\"show cashback option or retail discount\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
